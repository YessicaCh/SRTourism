{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR basada de Ontologia - Aprendizaje profundo \n",
    "El SR basado en Tourismo basado en Ontologia  se encuentra implementado en otro lenguaje y se abstrae los datos a traves de archivos .csv donde se guardan los datosluego son usados en esta implementacion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path = './model_context_pref.csv'):\n",
    "    dataset = pd.read_csv(path)\n",
    "    return dataset\n",
    "def preprocesing(dataset):\n",
    "    \n",
    "    user_id = dataset.iloc[:, 1:3].values\n",
    "    X = dataset.iloc[:, 3:5].values\n",
    "    Y = dataset.iloc[:, 5].values\n",
    "\n",
    "    return X,Y,user_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura de Sistema de recomendacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_etapa2(array_hidden_layers,input_,output): #selected the [128→64→32→16→8] hidden layers\n",
    "    model = keras.Sequential() #model.add(Embedding(4, 8, input_length=32))\n",
    "    model.add(layers.Dense(units = array_hidden_layers[0], kernel_initializer = 'uniform', \n",
    "                           activation = 'relu', input_dim = input_))\n",
    "\n",
    "    for idx in range(1,len(array_hidden_layers)):\n",
    "        model.add(layers.Dense(units = array_hidden_layers[idx] , kernel_initializer = 'uniform', \n",
    "                               activation = 'relu'))\n",
    "\n",
    "    model.add(layers.Dense(units = output, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt) #metrics = ['accuracy']\n",
    "\n",
    "    #print(\"PESOS: \",model.load_weights)\n",
    "\n",
    "    #keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)\n",
    "\n",
    "    print(model.summary())\n",
    "    #model.fit(X_train, y_train, batch_size = 10, epochs = 50)\n",
    "    #x = tf.ones((1, 4))\n",
    "    #y = model(x)\n",
    "\n",
    "    #y_pred = model.predict(X_test)\n",
    "\n",
    "    #print(y_pred)\n",
    "    return model\n",
    " \n",
    "\n",
    "def recomendaciones(y_true,y_pred,user_id_test):\n",
    "    dict_places = {'1p':0, '2p':1, '3p':2, '4p':3, '5p':4, '6p':5,'7p':6, '8p':7,'9p':8,'10p':9, '11p':10, '12p':11, '13p':12, '14p':13, '15p':14}\n",
    "    N=7\n",
    "    matriz_pred = np.zeros((19, 15))\n",
    "    matriz_true = np.zeros((19, 15))\n",
    "\n",
    "    for i in range(0,y_pred.shape[0]):\n",
    "     \n",
    "        score = y_pred[i][0]  #Se calculo \n",
    "        user  = user_id_test[i][0] #id de usuario \n",
    "        place  = dict_places[user_id_test[i][1]] #id del place \n",
    "\n",
    "        matriz_pred[user][place] = score\n",
    "        matriz_true[user][place] = y_true[i]\n",
    "    \n",
    "    data_pred = pd.DataFrame(matriz_pred, columns = dict_places.keys())\n",
    "    data_dict_pred = data_pred.to_dict('records')\n",
    "\n",
    "    data_true = pd.DataFrame(matriz_true, columns = dict_places.keys())\n",
    "    data_dict_true = data_true.to_dict('records')\n",
    "\n",
    "    array_pred = []\n",
    "    array_true = []\n",
    "\n",
    "    for idx in range(0,len(data_dict_true)):\n",
    "        array1 = data_dict_true[idx]\n",
    "        array2 = data_dict_pred[idx]\n",
    "       \n",
    "        pred_ = sorted(array2.items(), key=lambda item: item[1], reverse=True)\n",
    "        true_ = sorted(array1.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        array_pred.append(pred_[0:N])\n",
    "        array_true.append(true_[0:N])\n",
    "\n",
    "    return array_pred,array_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------METRICAS----------\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import average_precision_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel(n):\n",
    "    if n>0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def precision(y_true,y_pred):\n",
    "\n",
    "    result = y_true-y_pred\n",
    "    print(result)\n",
    "\n",
    "def mean_average_precision(y_pred,y_true):\n",
    "\n",
    "    MAP = []\n",
    "    N_total = len(y_pred)\n",
    "    sumatoria_gen = 0.0\n",
    "\n",
    "    for idx in  range(0,len(y_pred)):\n",
    "        k = 7\n",
    "\n",
    "        usuario_test = y_true[idx]\n",
    "        alfa = 1\n",
    "        array_7_res_true = {}\n",
    "        for i in range(0,k):\n",
    "            array_7_res_true[usuario_test[i][0]] = alfa\n",
    "            alfa = alfa - 0.14\n",
    "\n",
    "        usuario = y_pred[idx]\n",
    "        array_7_res_pred = []\n",
    "\n",
    "        for i in range(0,k):\n",
    "            array_7_res_pred.append(usuario[i][0])\n",
    "        \n",
    "        sumatoria=0.0\n",
    "        for place in array_7_res_pred:\n",
    "            if place in array_7_res_true:\n",
    "                sumatoria = sumatoria +1*array_7_res_true[place]\n",
    "        MAP.append(sumatoria/k)\n",
    "        sumatoria_gen+=sumatoria/k\n",
    "    \n",
    "    MAP_average = sumatoria_gen/N_total\n",
    "\n",
    "    return MAP_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_reciprocal_rank(y_pred,y_true):\n",
    "    sum_total = []\n",
    "    for idx,value in enumerate(y_true):\n",
    "\n",
    "        #Por usuario \n",
    "        array_true = {}\n",
    "        idx = 0\n",
    "        for indx, value in enumerate(value):\n",
    "            place = value[0]\n",
    "            array_true[place] = indx\n",
    "\n",
    "        cont = 0\n",
    "        sumatoria = 0\n",
    "        for id_,value in enumerate(y_pred[idx],1):\n",
    "            place_ = value[0]\n",
    "            if cont<1:\n",
    "                if place_ in  array_true and cont < 1 : \n",
    "                    sumatoria+= 1/id_\n",
    "                    cont+=1\n",
    "            else:\n",
    "                break\n",
    "        sum_total.append(sumatoria)\n",
    "    #print(sum_total)\n",
    "    return (sum(sum_total)/len(sum_total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_sr(y_pred,y_true):\n",
    "    sum_total = []\n",
    "    for idx,value in enumerate(y_true):\n",
    "\n",
    "        #Por usuario \n",
    "        array_true = {}\n",
    "        idx = 0\n",
    "        for indx, value in enumerate(value,1):\n",
    "            place = value[0]\n",
    "            if indx<8:\n",
    "                array_true[place] = indx\n",
    "\n",
    "        cont = 0\n",
    "        precision = 0\n",
    "        intersection = 0\n",
    "        for id_,value in enumerate(y_pred[idx],1):\n",
    "            place_ = value[0]\n",
    "            if id_<8:\n",
    "                if place_ in  array_true : \n",
    "                    intersection +=1 \n",
    "                cont+=1\n",
    "\n",
    "        precision+= (intersection/cont)\n",
    "            \n",
    "        sum_total.append(precision)\n",
    "    #print(sum_total)\n",
    "    return (sum(sum_total)/len(sum_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llamada a la arquitectura \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_hidden_layers = [64,128,256,512] #64,128 #,32,64[8,16,32,64] \n",
    "batch_size = 512#512-256\n",
    "epochs = 50\n",
    "output = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 173,633\n",
      "Trainable params: 173,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3082\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3013\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2933\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2830\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2701\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2543\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2350\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2120\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1851\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1544\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1209\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0864\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0549\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0334\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0321\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0547\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0754\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0750\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0609\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0448\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0338\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0295\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0304\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0338\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0379\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0411\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0428\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0428\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0413\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0385\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0350\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0314\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0284\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0264\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0258\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0265\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0279\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0289\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0289\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0277\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0257\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0236\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0220\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0208\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0208\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0207\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0204\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0197\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0186\n",
      "y_pred :  [[0.6469033 ]\n",
      " [0.4550717 ]\n",
      " [0.6717076 ]\n",
      " [0.6079219 ]\n",
      " [0.4550717 ]\n",
      " [0.6438027 ]\n",
      " [0.48125583]\n",
      " [0.4550717 ]\n",
      " [0.6717076 ]\n",
      " [0.4550717 ]\n",
      " [0.544129  ]\n",
      " [0.4550717 ]\n",
      " [0.6717076 ]\n",
      " [0.48623028]\n",
      " [0.4550717 ]\n",
      " [0.8537753 ]\n",
      " [0.8447773 ]\n",
      " [0.76200837]\n",
      " [0.86405873]\n",
      " [0.83041984]\n",
      " [0.9267197 ]\n",
      " [0.7777776 ]\n",
      " [0.6725736 ]\n",
      " [0.83941466]\n",
      " [0.7496042 ]\n",
      " [0.894909  ]\n",
      " [0.86405873]\n",
      " [0.8825689 ]\n",
      " [0.9267197 ]\n",
      " [0.9267197 ]\n",
      " [0.7850484 ]\n",
      " [0.50425845]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6079219 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.7850484 ]\n",
      " [0.50425845]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6079219 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [1.0171027 ]\n",
      " [0.93805146]\n",
      " [0.59728974]\n",
      " [0.79921603]\n",
      " [0.97100174]\n",
      " [1.0410908 ]\n",
      " [0.86405873]\n",
      " [1.0410908 ]\n",
      " [0.9575809 ]\n",
      " [1.0410908 ]\n",
      " [0.980588  ]\n",
      " [0.79009455]\n",
      " [0.70991087]\n",
      " [1.0410908 ]\n",
      " [1.0410908 ]\n",
      " [0.91255575]\n",
      " [0.91255575]\n",
      " [0.79921603]\n",
      " [0.79921603]\n",
      " [0.91255575]\n",
      " [1.0410908 ]\n",
      " [0.79009455]\n",
      " [0.6430598 ]\n",
      " [0.71041137]\n",
      " [0.81562614]\n",
      " [0.6430598 ]\n",
      " [0.6430598 ]\n",
      " [0.7467045 ]\n",
      " [1.0051041 ]\n",
      " [1.0410908 ]\n",
      " [0.8633495 ]\n",
      " [0.68799883]\n",
      " [0.59728974]\n",
      " [0.5760254 ]\n",
      " [0.92756665]\n",
      " [0.98777777]\n",
      " [0.81883585]\n",
      " [0.7673245 ]\n",
      " [0.7545659 ]\n",
      " [0.7496042 ]\n",
      " [0.70353156]\n",
      " [0.6725736 ]\n",
      " [0.7545659 ]\n",
      " [0.76200837]\n",
      " [0.97100174]\n",
      " [0.661581  ]\n",
      " [0.7154927 ]\n",
      " [0.5228647 ]\n",
      " [0.5760254 ]\n",
      " [0.6160528 ]\n",
      " [0.68799883]\n",
      " [0.70353156]\n",
      " [0.5760254 ]\n",
      " [0.49342868]\n",
      " [0.59728974]\n",
      " [0.544129  ]\n",
      " [0.5760254 ]\n",
      " [0.62705976]\n",
      " [0.6345011 ]\n",
      " [0.8633495 ]\n",
      " [0.9933698 ]\n",
      " [0.93805146]\n",
      " [0.84557396]\n",
      " [0.95182914]\n",
      " [0.97100174]\n",
      " [0.91445786]\n",
      " [0.8713363 ]\n",
      " [0.8713363 ]\n",
      " [0.9575809 ]\n",
      " [0.9933698 ]\n",
      " [0.980588  ]\n",
      " [0.95182914]\n",
      " [0.84557396]\n",
      " [0.87572974]\n",
      " [0.90659255]\n",
      " [0.6220981 ]\n",
      " [0.7434022 ]\n",
      " [0.76200837]\n",
      " [0.70353156]\n",
      " [0.7496042 ]\n",
      " [0.9267197 ]\n",
      " [0.6079219 ]\n",
      " [0.70353156]\n",
      " [0.7545659 ]\n",
      " [0.7247959 ]\n",
      " [0.70353156]\n",
      " [0.70353156]\n",
      " [0.7545659 ]\n",
      " [0.8753472 ]\n",
      " [0.9933698 ]\n",
      " [0.97100174]\n",
      " [0.8303568 ]\n",
      " [0.59728974]\n",
      " [0.544129  ]\n",
      " [0.8393548 ]\n",
      " [0.96261376]\n",
      " [0.544129  ]\n",
      " [0.544129  ]\n",
      " [0.71041137]\n",
      " [0.6999961 ]\n",
      " [0.8806632 ]\n",
      " [0.61600035]\n",
      " [0.5377497 ]\n",
      " [0.84557396]\n",
      " [0.90659255]\n",
      " [0.6526274 ]\n",
      " [0.7434022 ]\n",
      " [0.6717076 ]\n",
      " [0.4550717 ]\n",
      " [0.83041984]\n",
      " [0.79921603]\n",
      " [0.6430598 ]\n",
      " [0.73542804]\n",
      " [0.824958  ]\n",
      " [0.90659255]\n",
      " [0.84557396]\n",
      " [0.9245704 ]\n",
      " [1.0410908 ]\n",
      " [1.0410908 ]\n",
      " [0.8633495 ]\n",
      " [0.7932909 ]\n",
      " [0.6735783 ]\n",
      " [0.68799883]\n",
      " [0.544129  ]\n",
      " [0.6526274 ]\n",
      " [0.8447773 ]\n",
      " [0.62826604]\n",
      " [0.6725736 ]\n",
      " [0.7467045 ]\n",
      " [0.77178824]\n",
      " [0.6430598 ]\n",
      " [0.79009455]\n",
      " [0.5824048 ]\n",
      " [0.6055336 ]\n",
      " [0.6999961 ]\n",
      " [0.6469033 ]\n",
      " [0.6438027 ]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.6220981 ]\n",
      " [0.6717076 ]\n",
      " [0.6398163 ]\n",
      " [0.6398163 ]\n",
      " [0.6717076 ]\n",
      " [0.6469033 ]\n",
      " [0.6398163 ]\n",
      " [0.6398163 ]\n",
      " [0.62705976]\n",
      " [0.6345011 ]\n",
      " [0.6717076 ]\n",
      " [0.4550717 ]\n",
      " [0.53216785]\n",
      " [0.6717076 ]\n",
      " [0.6717076 ]\n",
      " [0.4982276 ]\n",
      " [0.75714344]\n",
      " [0.5760254 ]\n",
      " [0.6079219 ]\n",
      " [0.62705976]\n",
      " [0.6220981 ]\n",
      " [0.6079219 ]\n",
      " [0.4550717 ]\n",
      " [0.4550717 ]\n",
      " [0.59728974]\n",
      " [0.5724814 ]\n",
      " [0.59728974]\n",
      " [0.615896  ]\n",
      " [0.6717076 ]\n",
      " [0.544129  ]\n",
      " [0.6717076 ]\n",
      " [0.615896  ]\n",
      " [0.5122326 ]\n",
      " [0.5760254 ]\n",
      " [0.49342868]\n",
      " [0.6220981 ]\n",
      " [0.48125583]\n",
      " [0.6398163 ]\n",
      " [0.62705976]\n",
      " [0.59728974]\n",
      " [0.6220981 ]\n",
      " [0.59728974]\n",
      " [0.6438027 ]\n",
      " [0.6717076 ]\n",
      " [0.6079219 ]\n",
      " [0.4982276 ]\n",
      " [0.590267  ]\n",
      " [0.4550717 ]\n",
      " [0.6398163 ]\n",
      " [0.6717076 ]\n",
      " [0.5228647 ]\n",
      " [0.6079219 ]\n",
      " [0.6398163 ]\n",
      " [0.5377497 ]\n",
      " [0.56007725]\n",
      " [0.6469033 ]\n",
      " [0.7496042 ]\n",
      " [0.6610051 ]\n",
      " [0.56007725]\n",
      " [0.6079219 ]\n",
      " [0.7496042 ]\n",
      " [0.93805146]\n",
      " [0.70353156]\n",
      " [0.70353156]\n",
      " [0.70991087]\n",
      " [0.7496042 ]\n",
      " [0.6725736 ]\n",
      " [0.6725736 ]\n",
      " [0.62681824]\n",
      " [0.48623028]\n",
      " [0.92756665]\n",
      " [0.97100174]\n",
      " [0.7946505 ]\n",
      " [0.9267197 ]\n",
      " [0.79921603]\n",
      " [0.7932909 ]\n",
      " [0.7560577 ]\n",
      " [0.980588  ]\n",
      " [0.86405873]\n",
      " [0.9267197 ]\n",
      " [0.7496042 ]\n",
      " [0.9267197 ]\n",
      " [0.79921603]\n",
      " [0.9267197 ]\n",
      " [0.76200837]\n",
      " [0.8654782 ]]\n"
     ]
    }
   ],
   "source": [
    "#Cargar datos de entrenamiento \n",
    "    \n",
    "path_train = '../mod_recomendacion/datasetPropuesta/train.csv'\n",
    "dataset  = read_dataset(path_train)\n",
    "\n",
    "#print(\"Carga de datos\")\n",
    "#print(dataset)\n",
    "#print(\"\\n\")\n",
    "X_train,y_train,user_id = preprocesing(dataset) #X y Y entrenamiento \n",
    "#print(\"X_train ->\",X_train)\n",
    "#print(\"Y_train ->\",y_train)\n",
    "#print(\"user_id\",user_id)\n",
    "\n",
    "#Cargar datos de test\n",
    "path_test = '../mod_recomendacion/datasetPropuesta/test.csv'\n",
    "dataset_test  = read_dataset(path_test)\n",
    "X_test,y_test,user_id_test = preprocesing(dataset_test) #X y Y entrenamiento \n",
    "    \n",
    "model = dnn_etapa2(array_hidden_layers, X_train.shape[1], output)\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs)\n",
    "y_pred = model.predict(X_test)\n",
    "print('y_pred : ',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3p</td>\n",
       "      <td>9p</td>\n",
       "      <td>13p</td>\n",
       "      <td>1p</td>\n",
       "      <td>6p</td>\n",
       "      <td>4p</td>\n",
       "      <td>11p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6p</td>\n",
       "      <td>14p</td>\n",
       "      <td>15p</td>\n",
       "      <td>11p</td>\n",
       "      <td>13p</td>\n",
       "      <td>4p</td>\n",
       "      <td>12p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1p</td>\n",
       "      <td>3p</td>\n",
       "      <td>4p</td>\n",
       "      <td>5p</td>\n",
       "      <td>6p</td>\n",
       "      <td>7p</td>\n",
       "      <td>8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1p</td>\n",
       "      <td>3p</td>\n",
       "      <td>4p</td>\n",
       "      <td>5p</td>\n",
       "      <td>6p</td>\n",
       "      <td>7p</td>\n",
       "      <td>8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6p</td>\n",
       "      <td>8p</td>\n",
       "      <td>10p</td>\n",
       "      <td>14p</td>\n",
       "      <td>15p</td>\n",
       "      <td>1p</td>\n",
       "      <td>11p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6p</td>\n",
       "      <td>15p</td>\n",
       "      <td>14p</td>\n",
       "      <td>1p</td>\n",
       "      <td>2p</td>\n",
       "      <td>5p</td>\n",
       "      <td>10p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6p</td>\n",
       "      <td>15p</td>\n",
       "      <td>5p</td>\n",
       "      <td>1p</td>\n",
       "      <td>7p</td>\n",
       "      <td>8p</td>\n",
       "      <td>14p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15p</td>\n",
       "      <td>2p</td>\n",
       "      <td>7p</td>\n",
       "      <td>6p</td>\n",
       "      <td>1p</td>\n",
       "      <td>14p</td>\n",
       "      <td>13p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1p</td>\n",
       "      <td>10p</td>\n",
       "      <td>11p</td>\n",
       "      <td>5p</td>\n",
       "      <td>9p</td>\n",
       "      <td>4p</td>\n",
       "      <td>12p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15p</td>\n",
       "      <td>6p</td>\n",
       "      <td>14p</td>\n",
       "      <td>3p</td>\n",
       "      <td>9p</td>\n",
       "      <td>13p</td>\n",
       "      <td>5p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1p</td>\n",
       "      <td>6p</td>\n",
       "      <td>15p</td>\n",
       "      <td>11p</td>\n",
       "      <td>14p</td>\n",
       "      <td>5p</td>\n",
       "      <td>2p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13p</td>\n",
       "      <td>14p</td>\n",
       "      <td>12p</td>\n",
       "      <td>10p</td>\n",
       "      <td>15p</td>\n",
       "      <td>11p</td>\n",
       "      <td>5p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6p</td>\n",
       "      <td>1p</td>\n",
       "      <td>12p</td>\n",
       "      <td>10p</td>\n",
       "      <td>9p</td>\n",
       "      <td>15p</td>\n",
       "      <td>3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3p</td>\n",
       "      <td>4p</td>\n",
       "      <td>6p</td>\n",
       "      <td>9p</td>\n",
       "      <td>15p</td>\n",
       "      <td>1p</td>\n",
       "      <td>10p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6p</td>\n",
       "      <td>3p</td>\n",
       "      <td>4p</td>\n",
       "      <td>9p</td>\n",
       "      <td>10p</td>\n",
       "      <td>8p</td>\n",
       "      <td>11p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3p</td>\n",
       "      <td>5p</td>\n",
       "      <td>12p</td>\n",
       "      <td>13p</td>\n",
       "      <td>10p</td>\n",
       "      <td>15p</td>\n",
       "      <td>2p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3p</td>\n",
       "      <td>9p</td>\n",
       "      <td>15p</td>\n",
       "      <td>2p</td>\n",
       "      <td>8p</td>\n",
       "      <td>12p</td>\n",
       "      <td>4p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6p</td>\n",
       "      <td>15p</td>\n",
       "      <td>1p</td>\n",
       "      <td>5p</td>\n",
       "      <td>10p</td>\n",
       "      <td>9p</td>\n",
       "      <td>7p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7p</td>\n",
       "      <td>1p</td>\n",
       "      <td>3p</td>\n",
       "      <td>9p</td>\n",
       "      <td>11p</td>\n",
       "      <td>13p</td>\n",
       "      <td>15p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6\n",
       "0    3p   9p  13p   1p   6p   4p  11p\n",
       "1    6p  14p  15p  11p  13p   4p  12p\n",
       "2    1p   3p   4p   5p   6p   7p   8p\n",
       "3    1p   3p   4p   5p   6p   7p   8p\n",
       "4    6p   8p  10p  14p  15p   1p  11p\n",
       "5    6p  15p  14p   1p   2p   5p  10p\n",
       "6    6p  15p   5p   1p   7p   8p  14p\n",
       "7   15p   2p   7p   6p   1p  14p  13p\n",
       "8    1p  10p  11p   5p   9p   4p  12p\n",
       "9   15p   6p  14p   3p   9p  13p   5p\n",
       "10   1p   6p  15p  11p  14p   5p   2p\n",
       "11  13p  14p  12p  10p  15p  11p   5p\n",
       "12   6p   1p  12p  10p   9p  15p   3p\n",
       "13   3p   4p   6p   9p  15p   1p  10p\n",
       "14   6p   3p   4p   9p  10p   8p  11p\n",
       "15   3p   5p  12p  13p  10p  15p   2p\n",
       "16   3p   9p  15p   2p   8p  12p   4p\n",
       "17   6p  15p   1p   5p  10p   9p   7p\n",
       "18   7p   1p   3p   9p  11p  13p  15p"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_pred,array_true = recomendaciones(y_test,y_pred,user_id_test)\n",
    "\n",
    "predic_recomendation = {}\n",
    "idx_= 0\n",
    "for idx in array_pred:\n",
    "    predic_recomendation[idx_] = []\n",
    "    for colidx in idx:\n",
    "        predic_recomendation[idx_].append(colidx[0])\n",
    "    idx_+=1\n",
    "data_pref_pd = pd.DataFrame.from_dict(predic_recomendation, orient='index')\n",
    "data_pref_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_arquitectura(array_hidden_layers,batch_size,epochs):\n",
    "\n",
    "    #array_hidden_layers = [128,256,512] #64,128 #,32,64\n",
    "    #batch_size = 512#512-256\n",
    "    #epochs = 20\n",
    "    output = 1\n",
    "\n",
    "    #Cargar datos de entrenamiento \n",
    "    \n",
    "    path_train = '../mod_recomendacion/datasetPropuesta/train.csv'\n",
    "    dataset  = read_dataset(path_train)\n",
    "    #print(\"Carga de datos\")\n",
    "    #print(dataset)\n",
    "    #print(\"\\n\")\n",
    "    X_train,y_train,user_id = preprocesing(dataset) #X y Y entrenamiento \n",
    "    #print(\"X_train ->\",X_train)\n",
    "    #print(\"Y_train ->\",y_train)\n",
    "    #print(\"user_id\",user_id)\n",
    "\n",
    "    #Cargar datos de test\n",
    "    path_test = '../mod_recomendacion/datasetPropuesta/test.csv'\n",
    "    dataset_test  = read_dataset(path_test)\n",
    "    X_test,y_test,user_id_test = preprocesing(dataset_test) #X y Y entrenamiento \n",
    "    \n",
    "    model = dnn_etapa2(array_hidden_layers, X_train.shape[1], output)\n",
    "    model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #print(\"y_predic :\", y_pred)\n",
    "\n",
    "    #score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    #print(\"PREDIC :\", score)\n",
    "\n",
    "    #print('y_test : ',y_test)\n",
    "    print('y_pred : ',y_pred)\n",
    "    #print('user_id_test : ',user_id_test)\n",
    "\n",
    "\n",
    "    array_pred,array_true = recomendaciones(y_test,y_pred,user_id_test)\n",
    "    print(\"Recomendacion de ARquitectura\")\n",
    "    print(array_pred)\n",
    "    print(\"Recomendacion de verdadera\")\n",
    "    print(array_true)\n",
    "    \n",
    "    map_ = mean_average_precision(array_pred,array_true)\n",
    "    mrk = mean_reciprocal_rank(array_pred,array_true)\n",
    "    precision = precision_sr(array_pred,array_true)\n",
    "    \n",
    "    \n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"--------------------METRICAS ------------------\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "\n",
    "    mae  =  mean_absolute_error(y_test,y_pred)\n",
    "    # Calculation of Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_pred,y_test)\n",
    "\n",
    "    \n",
    "    print(\" MAE       : \", round(mae,3))\n",
    "    print(\" MSE       : \", round(mse,3))\n",
    "    print(\" MAPE      : \", round(mape,3))\n",
    "    print(\" MAP       : \", round(map_,3))\n",
    "    print(\" MRK       : \", round(mrk,3))\n",
    "    print(\" Precision : \", round(precision,3))\n",
    "\n",
    "\n",
    "    return [mae,mse,mape,map_,mrk,precision]\n",
    "\n",
    "    #metrica = mean_average_precision(y_pred2,y_test)\n",
    "    #print(metrica)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 173,633\n",
      "Trainable params: 173,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.3080\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2992\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2888\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2760\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2602\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2409\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2178\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1906\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1595\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1251\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0892\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0559\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0321\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0286\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0507\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0730\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0733\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0590\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0425\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0311\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0267\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0276\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0312\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0353\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0385\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0402\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0402\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0386\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0358\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0323\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0288\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0257\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0238\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0234\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0241\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0255\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0266\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0265\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0253\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0233\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0197\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0189\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0187\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0187\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0188\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0185\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0178\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0168\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0155\n",
      "y_pred :  [[0.6770183 ]\n",
      " [0.45604578]\n",
      " [0.70529675]\n",
      " [0.63258076]\n",
      " [0.45604578]\n",
      " [0.6734835 ]\n",
      " [0.48743582]\n",
      " [0.45604578]\n",
      " [0.70529675]\n",
      " [0.45604578]\n",
      " [0.55986476]\n",
      " [0.45604578]\n",
      " [0.70529675]\n",
      " [0.49327925]\n",
      " [0.45604578]\n",
      " [0.91099817]\n",
      " [0.9004055 ]\n",
      " [0.8088844 ]\n",
      " [0.9231056 ]\n",
      " [0.8832521 ]\n",
      " [0.9970902 ]\n",
      " [0.8191558 ]\n",
      " [0.70507175]\n",
      " [0.8941606 ]\n",
      " [0.7948793 ]\n",
      " [0.9601509 ]\n",
      " [0.9231056 ]\n",
      " [0.9453328 ]\n",
      " [0.9970902 ]\n",
      " [0.9970902 ]\n",
      " [0.83507156]\n",
      " [0.51442116]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.63258076]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.83507156]\n",
      " [0.51442116]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.63258076]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [1.0967449 ]\n",
      " [1.0014541 ]\n",
      " [0.6204614 ]\n",
      " [0.85129815]\n",
      " [1.0414642 ]\n",
      " [1.1253647 ]\n",
      " [0.9231056 ]\n",
      " [1.1253647 ]\n",
      " [1.0251013 ]\n",
      " [1.1253647 ]\n",
      " [1.0531518 ]\n",
      " [0.8357172 ]\n",
      " [0.74928963]\n",
      " [1.1253647 ]\n",
      " [1.1253647 ]\n",
      " [0.9809589 ]\n",
      " [0.9809589 ]\n",
      " [0.85129815]\n",
      " [0.85129815]\n",
      " [0.9809589 ]\n",
      " [1.1253647 ]\n",
      " [0.8357172 ]\n",
      " [0.669728  ]\n",
      " [0.741548  ]\n",
      " [0.86688447]\n",
      " [0.669728  ]\n",
      " [0.669728  ]\n",
      " [0.78322804]\n",
      " [1.0826212 ]\n",
      " [1.1253647 ]\n",
      " [0.9235492 ]\n",
      " [0.723359  ]\n",
      " [0.6204614 ]\n",
      " [0.5962227 ]\n",
      " [0.9886254 ]\n",
      " [1.0619177 ]\n",
      " [0.8707804 ]\n",
      " [0.81493783]\n",
      " [0.8004813 ]\n",
      " [0.7948793 ]\n",
      " [0.7418808 ]\n",
      " [0.70507175]\n",
      " [0.8004813 ]\n",
      " [0.8088844 ]\n",
      " [1.0414642 ]\n",
      " [0.69295853]\n",
      " [0.75577223]\n",
      " [0.53572667]\n",
      " [0.5962227 ]\n",
      " [0.6383471 ]\n",
      " [0.723359  ]\n",
      " [0.7418808 ]\n",
      " [0.5962227 ]\n",
      " [0.5016352 ]\n",
      " [0.6204614 ]\n",
      " [0.55986476]\n",
      " [0.5962227 ]\n",
      " [0.6543956 ]\n",
      " [0.66287905]\n",
      " [0.9235492 ]\n",
      " [1.0687355 ]\n",
      " [1.0014541 ]\n",
      " [0.8925427 ]\n",
      " [1.0181509 ]\n",
      " [1.0414642 ]\n",
      " [0.9726405 ]\n",
      " [0.92251563]\n",
      " [0.92251563]\n",
      " [1.0251013 ]\n",
      " [1.0687355 ]\n",
      " [1.0531518 ]\n",
      " [1.0181509 ]\n",
      " [0.8925427 ]\n",
      " [0.92745215]\n",
      " [0.9630801 ]\n",
      " [0.6487398 ]\n",
      " [0.78782034]\n",
      " [0.8088844 ]\n",
      " [0.7418808 ]\n",
      " [0.7948793 ]\n",
      " [0.9970902 ]\n",
      " [0.63258076]\n",
      " [0.7418808 ]\n",
      " [0.8004813 ]\n",
      " [0.76645684]\n",
      " [0.7418808 ]\n",
      " [0.7418808 ]\n",
      " [0.8004813 ]\n",
      " [0.9379557 ]\n",
      " [1.0687355 ]\n",
      " [1.0414642 ]\n",
      " [0.884249  ]\n",
      " [0.6204614 ]\n",
      " [0.55986476]\n",
      " [0.89484155]\n",
      " [1.0312375 ]\n",
      " [0.55986476]\n",
      " [0.55986476]\n",
      " [0.741548  ]\n",
      " [0.73776484]\n",
      " [0.9441299 ]\n",
      " [0.6370623 ]\n",
      " [0.5525931 ]\n",
      " [0.8925427 ]\n",
      " [0.9630801 ]\n",
      " [0.68141496]\n",
      " [0.78782034]\n",
      " [0.70529675]\n",
      " [0.45604578]\n",
      " [0.8832521 ]\n",
      " [0.85129815]\n",
      " [0.669728  ]\n",
      " [0.7786645 ]\n",
      " [0.87789345]\n",
      " [0.9630801 ]\n",
      " [0.8925427 ]\n",
      " [0.98496974]\n",
      " [1.1253647 ]\n",
      " [1.1253647 ]\n",
      " [0.9235492 ]\n",
      " [0.83961314]\n",
      " [0.70734656]\n",
      " [0.723359  ]\n",
      " [0.55986476]\n",
      " [0.68141496]\n",
      " [0.9004055 ]\n",
      " [0.65336895]\n",
      " [0.70507175]\n",
      " [0.78322804]\n",
      " [0.8134738 ]\n",
      " [0.669728  ]\n",
      " [0.8357172 ]\n",
      " [0.6034943 ]\n",
      " [0.6257018 ]\n",
      " [0.73776484]\n",
      " [0.6770183 ]\n",
      " [0.6734835 ]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.6487398 ]\n",
      " [0.70529675]\n",
      " [0.66893876]\n",
      " [0.66893876]\n",
      " [0.70529675]\n",
      " [0.6770183 ]\n",
      " [0.66893876]\n",
      " [0.66893876]\n",
      " [0.6543956 ]\n",
      " [0.66287905]\n",
      " [0.70529675]\n",
      " [0.45604578]\n",
      " [0.54623115]\n",
      " [0.70529675]\n",
      " [0.70529675]\n",
      " [0.5072841 ]\n",
      " [0.80325824]\n",
      " [0.5962227 ]\n",
      " [0.63258076]\n",
      " [0.6543956 ]\n",
      " [0.6487398 ]\n",
      " [0.63258076]\n",
      " [0.45604578]\n",
      " [0.45604578]\n",
      " [0.6204614 ]\n",
      " [0.592183  ]\n",
      " [0.6204614 ]\n",
      " [0.6416702 ]\n",
      " [0.70529675]\n",
      " [0.55986476]\n",
      " [0.70529675]\n",
      " [0.6416702 ]\n",
      " [0.5236821 ]\n",
      " [0.5962227 ]\n",
      " [0.5016352 ]\n",
      " [0.6487398 ]\n",
      " [0.48743582]\n",
      " [0.66893876]\n",
      " [0.6543956 ]\n",
      " [0.6204614 ]\n",
      " [0.6487398 ]\n",
      " [0.6204614 ]\n",
      " [0.6734835 ]\n",
      " [0.70529675]\n",
      " [0.63258076]\n",
      " [0.5072841 ]\n",
      " [0.6072446 ]\n",
      " [0.45604578]\n",
      " [0.66893876]\n",
      " [0.70529675]\n",
      " [0.53572667]\n",
      " [0.63258076]\n",
      " [0.66893876]\n",
      " [0.5525931 ]\n",
      " [0.5780437 ]\n",
      " [0.6770183 ]\n",
      " [0.7948793 ]\n",
      " [0.691641  ]\n",
      " [0.5780437 ]\n",
      " [0.63258076]\n",
      " [0.7948793 ]\n",
      " [1.0014541 ]\n",
      " [0.7418808 ]\n",
      " [0.7418808 ]\n",
      " [0.74928963]\n",
      " [0.7948793 ]\n",
      " [0.70507175]\n",
      " [0.70507175]\n",
      " [0.6498627 ]\n",
      " [0.49327925]\n",
      " [0.9886254 ]\n",
      " [1.0414642 ]\n",
      " [0.83970475]\n",
      " [0.9970902 ]\n",
      " [0.85129815]\n",
      " [0.83961314]\n",
      " [0.79438394]\n",
      " [1.0531518 ]\n",
      " [0.9231056 ]\n",
      " [0.9970902 ]\n",
      " [0.7948793 ]\n",
      " [0.9970902 ]\n",
      " [0.85129815]\n",
      " [0.9970902 ]\n",
      " [0.8088844 ]\n",
      " [0.9158834 ]]\n",
      "Recomendacion de ARquitectura\n",
      "[[('3p', 0.7052967548370361), ('9p', 0.7052967548370361), ('13p', 0.7052967548370361), ('1p', 0.6770182847976685), ('6p', 0.6734834909439087), ('4p', 0.6325807571411133), ('11p', 0.5598647594451904)], [('6p', 0.997090220451355), ('14p', 0.997090220451355), ('15p', 0.997090220451355), ('11p', 0.9601508975028992), ('13p', 0.9453328251838684), ('4p', 0.9231055974960327), ('12p', 0.9231055974960327)], [('1p', 0.8350715637207031), ('3p', 0.7052967548370361), ('4p', 0.7052967548370361), ('5p', 0.7052967548370361), ('6p', 0.7052967548370361), ('7p', 0.7052967548370361), ('8p', 0.7052967548370361)], [('1p', 0.8350715637207031), ('3p', 0.7052967548370361), ('4p', 0.7052967548370361), ('5p', 0.7052967548370361), ('6p', 0.7052967548370361), ('7p', 0.7052967548370361), ('8p', 0.7052967548370361)], [('6p', 1.1253646612167358), ('8p', 1.1253646612167358), ('10p', 1.1253646612167358), ('14p', 1.1253646612167358), ('15p', 1.1253646612167358), ('1p', 1.0967448949813843), ('11p', 1.0531518459320068)], [('6p', 1.1253646612167358), ('15p', 1.1253646612167358), ('14p', 1.0826212167739868), ('1p', 0.980958878993988), ('2p', 0.980958878993988), ('5p', 0.980958878993988), ('10p', 0.8668844699859619)], [('6p', 1.0619176626205444), ('15p', 1.0414642095565796), ('5p', 0.9886254072189331), ('1p', 0.9235491752624512), ('7p', 0.8707804083824158), ('8p', 0.8149378299713135), ('14p', 0.8088843822479248)], [('15p', 0.9235491752624512), ('2p', 0.7557722330093384), ('7p', 0.7418807744979858), ('6p', 0.7233589887619019), ('1p', 0.6929585337638855), ('14p', 0.6628790497779846), ('13p', 0.654395580291748)], [('1p', 1.0687354803085327), ('10p', 1.0687354803085327), ('11p', 1.0531518459320068), ('5p', 1.0414642095565796), ('9p', 1.0251013040542603), ('4p', 1.0181509256362915), ('12p', 1.0181509256362915)], [('15p', 1.0687354803085327), ('6p', 0.997090220451355), ('14p', 0.9379556775093079), ('3p', 0.8088843822479248), ('9p', 0.8004813194274902), ('13p', 0.8004813194274902), ('5p', 0.7948793172836304)], [('1p', 1.0414642095565796), ('6p', 1.0312374830245972), ('15p', 0.963080108165741), ('11p', 0.9441298842430115), ('5p', 0.8948415517807007), ('14p', 0.8925427198410034), ('2p', 0.8842489719390869)], [('13p', 1.1253646612167358), ('14p', 1.1253646612167358), ('12p', 0.9849697351455688), ('10p', 0.963080108165741), ('15p', 0.9235491752624512), ('11p', 0.8925427198410034), ('5p', 0.8832520842552185)], [('6p', 0.9004055261611938), ('1p', 0.839613139629364), ('12p', 0.8357172012329102), ('10p', 0.8134738206863403), ('9p', 0.7832280397415161), ('15p', 0.737764835357666), ('3p', 0.7233589887619019)], [('3p', 0.7052967548370361), ('4p', 0.7052967548370361), ('6p', 0.7052967548370361), ('9p', 0.7052967548370361), ('15p', 0.7052967548370361), ('1p', 0.6770182847976685), ('10p', 0.6770182847976685)], [('6p', 0.8032582402229309), ('3p', 0.7052967548370361), ('4p', 0.7052967548370361), ('9p', 0.654395580291748), ('10p', 0.6487398147583008), ('8p', 0.6325807571411133), ('11p', 0.6325807571411133)], [('3p', 0.7052967548370361), ('5p', 0.7052967548370361), ('12p', 0.6689387559890747), ('13p', 0.654395580291748), ('10p', 0.6487398147583008), ('15p', 0.6487398147583008), ('2p', 0.6416702270507812)], [('3p', 0.7052967548370361), ('9p', 0.7052967548370361), ('15p', 0.6770182847976685), ('2p', 0.6734834909439087), ('8p', 0.6689387559890747), ('12p', 0.6689387559890747), ('4p', 0.6325807571411133)], [('6p', 1.0014541149139404), ('15p', 0.9886254072189331), ('1p', 0.7948793172836304), ('5p', 0.7948793172836304), ('10p', 0.7948793172836304), ('9p', 0.7492896318435669), ('7p', 0.7418807744979858)], [('7p', 1.0531518459320068), ('1p', 1.0414642095565796), ('3p', 0.997090220451355), ('9p', 0.997090220451355), ('11p', 0.997090220451355), ('13p', 0.997090220451355), ('8p', 0.9231055974960327)]]\n",
      "Recomendacion de verdadera\n",
      "[[('9p', 0.9416666666666668), ('13p', 0.9416666666666668), ('3p', 0.9416666666666664), ('1p', 0.8694444444444444), ('6p', 0.8604166666666666), ('4p', 0.7559523809523809), ('11p', 0.5702380952380952)], [('6p', 1.4666666666666666), ('15p', 1.4666666666666666), ('14p', 1.4666666666666663), ('11p', 1.3738095238095236), ('13p', 1.3366666666666664), ('4p', 1.2809523809523808), ('12p', 1.2809523809523808)], [('1p', 1.1749999999999998), ('5p', 0.9416666666666668), ('6p', 0.9416666666666668), ('9p', 0.9416666666666668), ('10p', 0.9416666666666668), ('13p', 0.9416666666666668), ('15p', 0.9416666666666668)], [('1p', 1.1749999999999998), ('5p', 0.9416666666666668), ('6p', 0.9416666666666668), ('9p', 0.9416666666666668), ('10p', 0.9416666666666668), ('13p', 0.9416666666666668), ('15p', 0.9416666666666668)], [('6p', 1.6999999999999995), ('8p', 1.6999999999999995), ('10p', 1.6999999999999995), ('14p', 1.6999999999999995), ('15p', 1.6999999999999995), ('1p', 1.6277777777777775), ('11p', 1.514285714285714)], [('6p', 1.6999999999999995), ('15p', 1.6999999999999995), ('14p', 1.5916666666666666), ('1p', 1.4375), ('2p', 1.4375), ('5p', 1.4375), ('3p', 1.2041666666666666)], [('6p', 1.5375), ('15p', 1.4833333333333332), ('5p', 1.3388888888888888), ('1p', 1.2930555555555556), ('7p', 1.1589285714285715), ('8p', 1.1113095238095236), ('14p', 1.0958333333333332)], [('15p', 1.2930555555555556), ('2p', 0.9604166666666666), ('7p', 0.9255952380952379), ('6p', 0.8791666666666667), ('14p', 0.8333333333333334), ('1p', 0.8138888888888889), ('13p', 0.8116666666666666)], [('1p', 1.5555555555555554), ('10p', 1.5555555555555554), ('11p', 1.514285714285714), ('5p', 1.4833333333333332), ('9p', 1.44), ('4p', 1.4214285714285713), ('12p', 1.4214285714285713)], [('15p', 1.5555555555555554), ('6p', 1.4666666666666666), ('14p', 1.3291666666666666), ('3p', 1.0958333333333332), ('9p', 1.0741666666666667), ('13p', 1.0741666666666667), ('5p', 1.0597222222222222)], [('1p', 1.4833333333333332), ('6p', 1.4562499999999998), ('11p', 1.344642857142857), ('15p', 1.2666666666666666), ('5p', 1.2208333333333332), ('2p', 1.19375), ('14p', 1.0499999999999998)], [('13p', 1.6999999999999995), ('14p', 1.6999999999999995), ('12p', 1.3285714285714283), ('15p', 1.2930555555555556), ('10p', 1.2666666666666666), ('6p', 1.2041666666666666), ('5p', 1.1777777777777776)], [('6p', 1.2229166666666664), ('1p', 1.0763888888888888), ('12p', 1.0660714285714286), ('10p', 1.0041666666666669), ('9p', 0.9175), ('15p', 0.9152777777777776), ('3p', 0.8791666666666665)], [('6p', 0.9416666666666668), ('9p', 0.9416666666666668), ('15p', 0.9416666666666668), ('3p', 0.9416666666666664), ('4p', 0.9416666666666664), ('1p', 0.8694444444444444), ('10p', 0.8694444444444444)], [('6p', 1.09375), ('3p', 0.9416666666666664), ('4p', 0.9416666666666664), ('9p', 0.8116666666666666), ('10p', 0.7972222222222222), ('8p', 0.7559523809523809), ('11p', 0.7559523809523809)], [('5p', 0.9416666666666668), ('3p', 0.9416666666666664), ('12p', 0.8488095238095237), ('13p', 0.8116666666666666), ('10p', 0.7972222222222222), ('15p', 0.7972222222222222), ('2p', 0.7791666666666667)], [('9p', 0.9416666666666668), ('3p', 0.9416666666666664), ('15p', 0.8694444444444444), ('2p', 0.8604166666666666), ('8p', 0.8488095238095237), ('12p', 0.8488095238095237), ('4p', 0.7559523809523809)], [('6p', 1.3749999999999998), ('15p', 1.3388888888888888), ('1p', 1.0597222222222222), ('5p', 1.0597222222222222), ('10p', 1.0597222222222222), ('9p', 0.9441666666666666), ('7p', 0.9255952380952379)], [('7p', 1.514285714285714), ('1p', 1.4833333333333332), ('9p', 1.4666666666666666), ('13p', 1.4666666666666666), ('3p', 1.4666666666666663), ('11p', 1.4666666666666663), ('8p', 1.2809523809523808)]]\n",
      "-----------------------------------------------\n",
      "--------------------METRICAS ------------------\n",
      "-----------------------------------------------\n",
      " MAE       :  0.231\n",
      " MSE       :  0.072\n",
      " MAPE      :  0.284\n",
      " MAP       :  0.554\n",
      " MRK       :  0.671\n",
      " Precision :  0.526\n"
     ]
    }
   ],
   "source": [
    "array_hidden_layers = [64,128,256,512] #64,128 #,32,64[8,16,32,64] \n",
    "batch_size = 512#512-256\n",
    "epochs = 50\n",
    "output = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
